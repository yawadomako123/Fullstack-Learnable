# K-Means-Clustering

## [Vorlesungsquiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)

In dieser Lektion lernen Sie, wie Sie Cluster mit Scikit-learn und dem zuvor importierten nigerianischen Musikdatensatz erstellen. Wir werden die Grundlagen von K-Means f√ºr das Clustering behandeln. Denken Sie daran, dass es viele M√∂glichkeiten gibt, mit Clustern zu arbeiten, und die Methode, die Sie verwenden, von Ihren Daten abh√§ngt. Wir werden K-Means ausprobieren, da es die g√§ngigste Clustering-Technik ist. Lassen Sie uns beginnen!

Begriffe, die Sie lernen werden:

- Silhouettenbewertung
- Ellbogenmethode
- Tr√§gheit
- Varianz

## Einf√ºhrung

[K-Means-Clustering](https://wikipedia.org/wiki/K-means_clustering) ist eine Methode, die aus dem Bereich der Signalverarbeitung abgeleitet ist. Sie wird verwendet, um Gruppen von Daten in 'k' Cluster zu unterteilen und zu partitionieren, indem eine Reihe von Beobachtungen verwendet wird. Jede Beobachtung arbeitet daran, einen gegebenen Datenpunkt dem n√§chstgelegenen 'Mittelwert' oder dem Mittelpunkt eines Clusters zuzuordnen.

Die Cluster k√∂nnen als [Voronoi-Diagramme](https://wikipedia.org/wiki/Voronoi_diagram) visualisiert werden, die einen Punkt (oder 'Samen') und dessen entsprechende Region umfassen.

![voronoi diagram](../../../../translated_images/voronoi.1dc1613fb0439b9564615eca8df47a4bcd1ce06217e7e72325d2406ef2180795.de.png)

> Infografik von [Jen Looper](https://twitter.com/jenlooper)

Der K-Means-Clustering-Prozess [f√ºhrt einen dreistufigen Prozess aus](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Der Algorithmus w√§hlt k-Mittelwerte durch Sampling aus dem Datensatz aus. Danach wiederholt er:
    1. Er weist jede Probe dem n√§chstgelegenen Schwerpunkt zu.
    2. Er erstellt neue Schwerpunkte, indem er den Mittelwert aller Proben berechnet, die den vorherigen Schwerpunkten zugewiesen wurden.
    3. Dann berechnet er die Differenz zwischen den neuen und alten Schwerpunkten und wiederholt den Vorgang, bis die Schwerpunkte stabilisiert sind.

Ein Nachteil der Verwendung von K-Means besteht darin, dass Sie 'k' festlegen m√ºssen, also die Anzahl der Schwerpunkte. Gl√ºcklicherweise hilft die 'Ellbogenmethode', einen guten Startwert f√ºr 'k' zu sch√§tzen. Das werden Sie gleich ausprobieren.

## Voraussetzungen

Sie werden in dieser Lektion mit der Datei [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) arbeiten, die den Datenimport und die vorl√§ufige Bereinigung enth√§lt, die Sie in der letzten Lektion durchgef√ºhrt haben.

## √úbung - Vorbereitung

Beginnen Sie damit, sich die Songdaten noch einmal anzusehen.

1. Erstellen Sie ein Boxplot, indem Sie `boxplot()` f√ºr jede Spalte aufrufen:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Diese Daten sind etwas verrauscht: Durch die Beobachtung jeder Spalte als Boxplot k√∂nnen Sie Ausrei√üer erkennen.

    ![outliers](../../../../translated_images/boxplots.8228c29dabd0f29227dd38624231a175f411f1d8d4d7c012cb770e00e4fdf8b6.de.png)

Sie k√∂nnten den Datensatz durchgehen und diese Ausrei√üer entfernen, aber das w√ºrde die Daten ziemlich minimal machen.

1. W√§hlen Sie vorerst aus, welche Spalten Sie f√ºr Ihre Clustering-√úbung verwenden m√∂chten. W√§hlen Sie solche mit √§hnlichen Bereichen und kodieren Sie die Spalte `artist_top_genre` als numerische Daten:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Jetzt m√ºssen Sie entscheiden, wie viele Cluster Sie anvisieren m√∂chten. Sie wissen, dass es 3 Musikgenres gibt, die wir aus dem Datensatz herausgearbeitet haben, also versuchen wir es mit 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Sie sehen ein Array, das die vorhergesagten Cluster (0, 1 oder 2) f√ºr jede Zeile des DataFrames ausgibt.

1. Verwenden Sie dieses Array, um eine 'Silhouettenbewertung' zu berechnen:

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silhouettenbewertung

Suchen Sie nach einer Silhouettenbewertung, die n√§her an 1 liegt. Diese Bewertung variiert von -1 bis 1, und wenn der Wert 1 betr√§gt, ist das Cluster dicht und gut von anderen Clustern getrennt. Ein Wert nahe 0 repr√§sentiert √ºberlappende Cluster mit Proben, die sehr nah an der Entscheidungsgrenze der benachbarten Cluster liegen. [(Quelle)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Unsere Bewertung betr√§gt **.53**, also genau in der Mitte. Das deutet darauf hin, dass unsere Daten nicht besonders gut f√ºr diese Art von Clustering geeignet sind, aber lassen Sie uns weitermachen.

### √úbung - Modell erstellen

1. Importieren Sie `KMeans` und starten Sie den Clustering-Prozess.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Es gibt hier einige Teile, die einer Erkl√§rung bed√ºrfen.

    > üéì range: Dies sind die Iterationen des Clustering-Prozesses

    > üéì random_state: "Bestimmt die Zufallszahlengenerierung f√ºr die Initialisierung des Schwerpunkts." [Quelle](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > üéì WCSS: "Innerhalb der Cluster summierte Quadrate" messen den quadratischen Durchschnittsabstand aller Punkte innerhalb eines Clusters zum Cluster-Schwerpunkt. [Quelle](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > üéì Tr√§gheit: K-Means-Algorithmen versuchen, Schwerpunkte auszuw√§hlen, um die 'Tr√§gheit' zu minimieren, "ein Ma√ü daf√ºr, wie intern koh√§rent Cluster sind." [Quelle](https://scikit-learn.org/stable/modules/clustering.html). Der Wert wird bei jeder Iteration der wcss-Variablen hinzugef√ºgt.

    > üéì k-means++: In [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) k√∂nnen Sie die 'k-means++'-Optimierung verwenden, die "die Schwerpunkte in der Regel weit voneinander entfernt initialisiert, was wahrscheinlich bessere Ergebnisse als die zuf√§llige Initialisierung liefert."

### Ellbogenmethode

Fr√ºher haben Sie vermutet, dass Sie, da Sie 3 Musikgenres anvisiert haben, 3 Cluster w√§hlen sollten. Ist das wirklich der Fall?

1. Verwenden Sie die 'Ellbogenmethode', um sicherzustellen.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Verwenden Sie die `wcss`-Variable, die Sie im vorherigen Schritt erstellt haben, um ein Diagramm zu erstellen, das zeigt, wo der 'Knick' im Ellbogen ist, was die optimale Anzahl von Clustern anzeigt. Vielleicht sind es **3**!

    ![elbow method](../../../../translated_images/elbow.72676169eed744ff03677e71334a16c6b8f751e9e716e3d7f40dd7cdef674cca.de.png)

## √úbung - Cluster anzeigen

1. Versuchen Sie den Prozess erneut, diesmal mit drei Clustern, und zeigen Sie die Cluster als Streudiagramm an:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. √úberpr√ºfen Sie die Genauigkeit des Modells:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Die Genauigkeit dieses Modells ist nicht sehr gut, und die Form der Cluster gibt Ihnen einen Hinweis darauf, warum.

    ![clusters](../../../../translated_images/clusters.b635354640d8e4fd4a49ef545495518e7be76172c97c13bd748f5b79f171f69a.de.png)

    Diese Daten sind zu unausgewogen, zu wenig korreliert und es gibt zu viel Varianz zwischen den Spaltenwerten, um gut zu clustern. Tats√§chlich werden die Cluster, die sich bilden, wahrscheinlich stark von den drei Genre-Kategorien beeinflusst oder verzerrt, die wir oben definiert haben. Das war ein Lernprozess!

    In der Dokumentation von Scikit-learn k√∂nnen Sie sehen, dass ein Modell wie dieses, mit nicht gut abgegrenzten Clustern, ein 'Varianzproblem' hat:

    ![problem models](../../../../translated_images/problems.f7fb539ccd80608e1f35c319cf5e3ad1809faa3c08537aead8018c6b5ba2e33a.de.png)
    > Infografik von Scikit-learn

## Varianz

Varianz wird definiert als "der Durchschnitt der quadrierten Abweichungen vom Mittelwert" [(Quelle)](https://www.mathsisfun.com/data/standard-deviation.html). Im Kontext dieses Clustering-Problems bezieht es sich auf Daten, bei denen die Zahlen unseres Datensatzes dazu neigen, sich zu stark vom Mittelwert zu entfernen.

‚úÖ Dies ist ein gro√üartiger Moment, um √ºber all die M√∂glichkeiten nachzudenken, wie Sie dieses Problem beheben k√∂nnten. Daten ein wenig mehr anpassen? Andere Spalten verwenden? Einen anderen Algorithmus verwenden? Hinweis: Versuchen Sie, [Ihre Daten zu skalieren](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/), um sie zu normalisieren und andere Spalten zu testen.

> Versuchen Sie diesen '[Varianzrechner](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', um das Konzept etwas besser zu verstehen.

---

## üöÄHerausforderung

Verbringen Sie etwas Zeit mit diesem Notizbuch und passen Sie die Parameter an. K√∂nnen Sie die Genauigkeit des Modells verbessern, indem Sie die Daten weiter bereinigen (zum Beispiel Ausrei√üer entfernen)? Sie k√∂nnen Gewichte verwenden, um bestimmten Datenproben mehr Gewicht zu geben. Was k√∂nnen Sie sonst noch tun, um bessere Cluster zu erstellen?

Hinweis: Versuchen Sie, Ihre Daten zu skalieren. Es gibt kommentierten Code im Notizbuch, der eine Standard-Skalierung hinzuf√ºgt, um die Daten-Spalten einander √§hnlicher in Bezug auf den Bereich zu machen. Sie werden feststellen, dass, w√§hrend die Silhouettenbewertung sinkt, der 'Knick' im Ellbogendiagramm sich gl√§ttet. Das liegt daran, dass das Belassen der Daten im unskalierten Zustand Daten mit weniger Varianz mehr Gewicht verleiht. Lesen Sie ein wenig mehr √ºber dieses Problem [hier](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Nachlesungsquiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)

## √úberpr√ºfung & Selbststudium

Werfen Sie einen Blick auf einen K-Means-Simulator [wie diesen hier](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Sie k√∂nnen dieses Tool verwenden, um Beispieldatenpunkte zu visualisieren und deren Schwerpunkte zu bestimmen. Sie k√∂nnen die Zuf√§lligkeit der Daten, die Anzahl der Cluster und die Anzahl der Schwerpunkte bearbeiten. Hilft Ihnen das, eine Vorstellung davon zu bekommen, wie die Daten gruppiert werden k√∂nnen?

Sehen Sie sich auch [dieses Handout zu K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) von Stanford an.

## Aufgabe

[Versuchen Sie verschiedene Clustering-Methoden](assignment.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mit maschinellen KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als die ma√ügebliche Quelle betrachtet werden. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Verantwortung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung resultieren.