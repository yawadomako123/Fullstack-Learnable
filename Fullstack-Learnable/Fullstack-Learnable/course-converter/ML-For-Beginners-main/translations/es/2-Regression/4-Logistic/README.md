# Regresi√≥n log√≠stica para predecir categor√≠as

![Infograf√≠a de regresi√≥n log√≠stica vs. regresi√≥n lineal](../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.es.png)

## [Cuestionario previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introducci√≥n

En esta √∫ltima lecci√≥n sobre Regresi√≥n, una de las t√©cnicas b√°sicas _cl√°sicas_ de ML, echaremos un vistazo a la Regresi√≥n Log√≠stica. Utilizar√≠as esta t√©cnica para descubrir patrones y predecir categor√≠as binarias. ¬øEs este caramelo de chocolate o no? ¬øEs esta enfermedad contagiosa o no? ¬øElegir√° este cliente este producto o no?

En esta lecci√≥n, aprender√°s:

- Una nueva biblioteca para visualizaci√≥n de datos
- T√©cnicas para la regresi√≥n log√≠stica

‚úÖ Profundiza tu comprensi√≥n sobre el trabajo con este tipo de regresi√≥n en este [m√≥dulo de aprendizaje](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Prerrequisito

Habiendo trabajado con los datos de las calabazas, ahora estamos lo suficientemente familiarizados con ellos para darnos cuenta de que hay una categor√≠a binaria con la que podemos trabajar: `Color`.

Construyamos un modelo de regresi√≥n log√≠stica para predecir, dado algunas variables, _de qu√© color es probable que sea una calabaza_ (naranja üéÉ o blanca üëª).

> ¬øPor qu√© estamos hablando de clasificaci√≥n binaria en una lecci√≥n sobre regresi√≥n? Solo por conveniencia ling√º√≠stica, ya que la regresi√≥n log√≠stica es [realmente un m√©todo de clasificaci√≥n](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), aunque basado en lo lineal. Aprende sobre otras formas de clasificar datos en el pr√≥ximo grupo de lecciones.

## Definir la pregunta

Para nuestros prop√≥sitos, expresaremos esto como un binario: 'Blanco' o 'No Blanco'. Tambi√©n hay una categor√≠a 'rayada' en nuestro conjunto de datos, pero hay pocos casos de ella, por lo que no la usaremos. Desaparece una vez que eliminamos los valores nulos del conjunto de datos, de todos modos.

> üéÉ Dato curioso, a veces llamamos a las calabazas blancas 'calabazas fantasma'. No son muy f√°ciles de tallar, por lo que no son tan populares como las naranjas, ¬°pero se ven geniales! As√≠ que tambi√©n podr√≠amos reformular nuestra pregunta como: 'Fantasma' o 'No Fantasma'. üëª

## Sobre la regresi√≥n log√≠stica

La regresi√≥n log√≠stica difiere de la regresi√≥n lineal, de la que aprendiste anteriormente, en algunos aspectos importantes.

[![ML para principiantes - Comprender la Regresi√≥n Log√≠stica para la Clasificaci√≥n de Aprendizaje Autom√°tico](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML para principiantes - Comprender la Regresi√≥n Log√≠stica para la Clasificaci√≥n de Aprendizaje Autom√°tico")

> üé• Haz clic en la imagen de arriba para una breve descripci√≥n en video de la regresi√≥n log√≠stica.

### Clasificaci√≥n binaria

La regresi√≥n log√≠stica no ofrece las mismas caracter√≠sticas que la regresi√≥n lineal. La primera ofrece una predicci√≥n sobre una categor√≠a binaria ("blanco o no blanco"), mientras que la segunda es capaz de predecir valores continuos, por ejemplo, dado el origen de una calabaza y el tiempo de cosecha, _cu√°nto subir√° su precio_.

![Modelo de clasificaci√≥n de calabazas](../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.es.png)
> Infograf√≠a por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Otras clasificaciones

Hay otros tipos de regresi√≥n log√≠stica, incluyendo la multinomial y la ordinal:

- **Multinomial**, que implica tener m√°s de una categor√≠a - "Naranja, Blanco y Rayada".
- **Ordinal**, que implica categor√≠as ordenadas, √∫til si quisi√©ramos ordenar nuestros resultados l√≥gicamente, como nuestras calabazas que est√°n ordenadas por un n√∫mero finito de tama√±os (mini,peque√±o,mediano,grande,xl,xxl).

![Regresi√≥n multinomial vs ordinal](../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.es.png)

### Las variables NO TIENEN que correlacionar

¬øRecuerdas c√≥mo la regresi√≥n lineal funcionaba mejor con variables m√°s correlacionadas? La regresi√≥n log√≠stica es lo opuesto: las variables no tienen que alinearse. Eso funciona para estos datos que tienen correlaciones algo d√©biles.

### Necesitas muchos datos limpios

La regresi√≥n log√≠stica dar√° resultados m√°s precisos si usas m√°s datos; nuestro peque√±o conjunto de datos no es √≥ptimo para esta tarea, as√≠ que tenlo en cuenta.

[![ML para principiantes - An√°lisis y Preparaci√≥n de Datos para Regresi√≥n Log√≠stica](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML para principiantes - An√°lisis y Preparaci√≥n de Datos para Regresi√≥n Log√≠stica")

> üé• Haz clic en la imagen de arriba para una breve descripci√≥n en video de la preparaci√≥n de datos para la regresi√≥n lineal

‚úÖ Piensa en los tipos de datos que se prestar√≠an bien a la regresi√≥n log√≠stica

## Ejercicio - limpiar los datos

Primero, limpia un poco los datos, eliminando los valores nulos y seleccionando solo algunas de las columnas:

1. Agrega el siguiente c√≥digo:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Siempre puedes echar un vistazo a tu nuevo dataframe:

    ```python
    pumpkins.info
    ```

### Visualizaci√≥n - gr√°fico categ√≥rico

Para este momento, ya has cargado el [cuaderno inicial](../../../../2-Regression/4-Logistic/notebook.ipynb) con los datos de las calabazas una vez m√°s y los has limpiado para preservar un conjunto de datos que contiene algunas variables, incluyendo `Color`. Vamos a visualizar el dataframe en el cuaderno utilizando una biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que est√° construida sobre Matplotlib que usamos anteriormente.

Seaborn ofrece algunas formas interesantes de visualizar tus datos. Por ejemplo, puedes comparar distribuciones de los datos para cada `Variety` y `Color` en un gr√°fico categ√≥rico.

1. Crea un gr√°fico de este tipo usando `catplot` function, using our pumpkin data `pumpkins`, y especificando un mapeo de color para cada categor√≠a de calabaza (naranja o blanca):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Una cuadr√≠cula de datos visualizados](../../../../translated_images/pumpkins_catplot_1.c55c409b71fea2ecc01921e64b91970542101f90bcccfa4aa3a205db8936f48b.es.png)

    Al observar los datos, puedes ver c√≥mo los datos de Color se relacionan con Variety.

    ‚úÖ Dado este gr√°fico categ√≥rico, ¬øcu√°les son algunas exploraciones interesantes que puedes imaginar?

### Preprocesamiento de datos: codificaci√≥n de caracter√≠sticas y etiquetas

Nuestro conjunto de datos de calabazas contiene valores de cadena para todas sus columnas. Trabajar con datos categ√≥ricos es intuitivo para los humanos pero no para las m√°quinas. Los algoritmos de aprendizaje autom√°tico funcionan bien con n√∫meros. Por eso la codificaci√≥n es un paso muy importante en la fase de preprocesamiento de datos, ya que nos permite convertir datos categ√≥ricos en datos num√©ricos, sin perder informaci√≥n. Una buena codificaci√≥n lleva a construir un buen modelo.

Para la codificaci√≥n de caracter√≠sticas hay dos tipos principales de codificadores:

1. Codificador ordinal: se adapta bien a las variables ordinales, que son variables categ√≥ricas donde sus datos siguen un orden l√≥gico, como la columna `Item Size` en nuestro conjunto de datos. Crea un mapeo tal que cada categor√≠a est√° representada por un n√∫mero, que es el orden de la categor√≠a en la columna.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificador categ√≥rico: se adapta bien a las variables nominales, que son variables categ√≥ricas donde sus datos no siguen un orden l√≥gico, como todas las caracter√≠sticas diferentes de `Item Size` en nuestro conjunto de datos. Es una codificaci√≥n de una sola vez, lo que significa que cada categor√≠a est√° representada por una columna binaria: la variable codificada es igual a 1 si la calabaza pertenece a esa Variety y 0 en caso contrario.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```
Luego, `ColumnTransformer` se utiliza para combinar m√∫ltiples codificadores en un solo paso y aplicarlos a las columnas apropiadas.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```
Por otro lado, para codificar la etiqueta, utilizamos la clase `LabelEncoder` de scikit-learn, que es una clase de utilidad para ayudar a normalizar las etiquetas de modo que contengan solo valores entre 0 y n_clases-1 (aqu√≠, 0 y 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```
Una vez que hemos codificado las caracter√≠sticas y la etiqueta, podemos fusionarlas en un nuevo dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```
‚úÖ ¬øCu√°les son las ventajas de usar un codificador ordinal para la columna `Item Size` column?

### Analyse relationships between variables

Now that we have pre-processed our data, we can analyse the relationships between the features and the label to grasp an idea of how well the model will be able to predict the label given the features.
The best way to perform this kind of analysis is plotting the data. We'll be using again the Seaborn `catplot` function, to visualize the relationships between `Item Size`,  `Variety` y `Color` en un gr√°fico categ√≥rico? Para plotear mejor los datos, usaremos la columna codificada `Item Size` column and the unencoded `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```
![Un catplot de datos visualizados](../../../../translated_images/pumpkins_catplot_2.87a354447880b3889278155957f8f60dd63db4598de5a6d0fda91c334d31f9f1.es.png)

### Usar un gr√°fico de enjambre

Dado que Color es una categor√≠a binaria (Blanco o No), necesita 'un [enfoque especializado](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para la visualizaci√≥n'. Hay otras formas de visualizar la relaci√≥n de esta categor√≠a con otras variables.

Puedes visualizar variables una al lado de la otra con gr√°ficos de Seaborn.

1. Prueba un gr√°fico de 'enjambre' para mostrar la distribuci√≥n de valores:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un enjambre de datos visualizados](../../../../translated_images/swarm_2.efeacfca536c2b577dc7b5f8891f28926663fbf62d893ab5e1278ae734ca104e.es.png)

**Ten cuidado**: el c√≥digo anterior puede generar una advertencia, ya que Seaborn no puede representar tal cantidad de puntos de datos en un gr√°fico de enjambre. Una posible soluci√≥n es disminuir el tama√±o del marcador, utilizando el par√°metro 'size'. Sin embargo, ten en cuenta que esto afecta la legibilidad del gr√°fico.

> **üßÆ Mu√©strame las matem√°ticas**
>
> La regresi√≥n log√≠stica se basa en el concepto de 'm√°xima verosimilitud' utilizando [funciones sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Una 'Funci√≥n Sigmoide' en un gr√°fico se ve como una forma de 'S'. Toma un valor y lo mapea a alg√∫n lugar entre 0 y 1. Su curva tambi√©n se llama 'curva log√≠stica'. Su f√≥rmula se ve as√≠:
>
> ![funci√≥n log√≠stica](../../../../translated_images/sigmoid.8b7ba9d095c789cf72780675d0d1d44980c3736617329abfc392dfc859799704.es.png)
>
> donde el punto medio de la sigmoide se encuentra en el punto 0 de x, L es el valor m√°ximo de la curva, y k es la inclinaci√≥n de la curva. Si el resultado de la funci√≥n es mayor a 0.5, la etiqueta en cuesti√≥n recibir√° la clase '1' de la elecci√≥n binaria. Si no, se clasificar√° como '0'.

## Construye tu modelo

Construir un modelo para encontrar estas clasificaciones binarias es sorprendentemente sencillo en Scikit-learn.

[![ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos")

> üé• Haz clic en la imagen de arriba para una breve descripci√≥n en video de la construcci√≥n de un modelo de regresi√≥n lineal

1. Selecciona las variables que deseas utilizar en tu modelo de clasificaci√≥n y divide los conjuntos de entrenamiento y prueba llamando a `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Ahora puedes entrenar tu modelo, llamando a `fit()` con tus datos de entrenamiento, e imprimir su resultado:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Echa un vistazo al puntaje de tu modelo. No est√° mal, considerando que solo tienes alrededor de 1000 filas de datos:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Mejor comprensi√≥n mediante una matriz de confusi√≥n

Aunque puedes obtener un informe de puntuaci√≥n [t√©rminos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimiendo los elementos anteriores, podr√≠as entender mejor tu modelo usando una [matriz de confusi√≥n](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para ayudarnos a comprender c√≥mo est√° funcionando el modelo.

> üéì Una '[matriz de confusi√≥n](https://wikipedia.org/wiki/Confusion_matrix)' (o 'matriz de error') es una tabla que expresa los verdaderos vs. falsos positivos y negativos de tu modelo, evaluando as√≠ la precisi√≥n de las predicciones.

1. Para usar una m√©trica de confusi√≥n, llama a `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Echa un vistazo a la matriz de confusi√≥n de tu modelo:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

En Scikit-learn, las filas de las matrices de confusi√≥n (eje 0) son etiquetas reales y las columnas (eje 1) son etiquetas predichas.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

¬øQu√© est√° pasando aqu√≠? Digamos que nuestro modelo se le pide clasificar calabazas entre dos categor√≠as binarias, categor√≠a 'blanco' y categor√≠a 'no-blanco'.

- Si tu modelo predice una calabaza como no blanca y pertenece a la categor√≠a 'no-blanco' en realidad, lo llamamos un verdadero negativo, mostrado por el n√∫mero superior izquierdo.
- Si tu modelo predice una calabaza como blanca y pertenece a la categor√≠a 'no-blanco' en realidad, lo llamamos un falso negativo, mostrado por el n√∫mero inferior izquierdo.
- Si tu modelo predice una calabaza como no blanca y pertenece a la categor√≠a 'blanco' en realidad, lo llamamos un falso positivo, mostrado por el n√∫mero superior derecho.
- Si tu modelo predice una calabaza como blanca y pertenece a la categor√≠a 'blanco' en realidad, lo llamamos un verdadero positivo, mostrado por el n√∫mero inferior derecho.

Como habr√°s adivinado, es preferible tener un mayor n√∫mero de verdaderos positivos y verdaderos negativos y un menor n√∫mero de falsos positivos y falsos negativos, lo que implica que el modelo funciona mejor.

¬øC√≥mo se relaciona la matriz de confusi√≥n con la precisi√≥n y el recall? Recuerda, el informe de clasificaci√≥n impreso anteriormente mostr√≥ precisi√≥n (0.85) y recall (0.67).

Precisi√≥n = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

‚úÖ P: Seg√∫n la matriz de confusi√≥n, ¬øc√≥mo le fue al modelo? R: No est√° mal; hay un buen n√∫mero de verdaderos negativos pero tambi√©n algunos falsos negativos.

Volvamos a los t√©rminos que vimos anteriormente con la ayuda del mapeo TP/TN y FP/FN de la matriz de confusi√≥n:

üéì Precisi√≥n: TP/(TP + FP) La fracci√≥n de instancias relevantes entre las instancias recuperadas (por ejemplo, qu√© etiquetas fueron bien etiquetadas)

üéì Recall: TP/(TP + FN) La fracci√≥n de instancias relevantes que fueron recuperadas, ya sea bien etiquetadas o no

üéì f1-score: (2 * precisi√≥n * recall)/(precisi√≥n + recall) Un promedio ponderado de la precisi√≥n y el recall, siendo el mejor 1 y el peor 0

üéì Soporte: El n√∫mero de ocurrencias de cada etiqueta recuperada

üéì Exactitud: (TP + TN)/(TP + TN + FP + FN) El porcentaje de etiquetas predichas con precisi√≥n para una muestra.

üéì Promedio Macro: El c√°lculo de las m√©tricas medias no ponderadas para cada etiqueta, sin tener en cuenta el desequilibrio de las etiquetas.

üéì Promedio Ponderado: El c√°lculo de las m√©tricas medias para cada etiqueta, teniendo en cuenta el desequilibrio de las etiquetas ponder√°ndolas por su soporte (el n√∫mero de instancias verdaderas para cada etiqueta).

‚úÖ ¬øPuedes pensar en qu√© m√©trica deber√≠as observar si deseas que tu modelo reduzca el n√∫mero de falsos negativos?

## Visualiza la curva ROC de este modelo

[![ML para principiantes - Analizando el Rendimiento de la Regresi√≥n Log√≠stica con Curvas ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML para principiantes - Analizando el Rendimiento de la Regresi√≥n Log√≠stica con Curvas ROC")

> üé• Haz clic en la imagen de arriba para una breve descripci√≥n en video de las curvas ROC

Hagamos una visualizaci√≥n m√°s para ver la llamada curva 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Usando Matplotlib, grafica la [Curva Caracter√≠stica Operativa del Receptor](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) o ROC del modelo. Las curvas ROC se utilizan a menudo para obtener una vista de la salida de un clasificador en t√©rminos de sus verdaderos vs. falsos positivos. "Las curvas ROC generalmente presentan la tasa de verdaderos positivos en el eje Y, y la tasa de falsos positivos en el eje X". Por lo tanto, la inclinaci√≥n de la curva y el espacio entre la l√≠nea del punto medio y la curva importan: deseas una curva que r√°pidamente se dirija hacia arriba y sobre la l√≠nea. En nuestro caso, hay falsos positivos al principio, y luego la l√≠nea se dirige hacia arriba y sobre correctamente:

![ROC](../../../../translated_images/ROC_2.777f20cdfc4988ca683ade6850ac832cb70c96c12f1b910d294f270ef36e1a1c.es.png)

Finalmente, usa la [API `roc_auc_score` de Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) para calcular el '√Årea Bajo la Curva' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
El resultado es `0.9749908725812341`. Dado que el AUC var√≠a de 0 a 1, deseas un puntaje alto, ya que un modelo que es 100% correcto en sus predicciones tendr√° un AUC de 1; en este caso

**Descargo de responsabilidad**:
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n humana profesional. No nos hacemos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.