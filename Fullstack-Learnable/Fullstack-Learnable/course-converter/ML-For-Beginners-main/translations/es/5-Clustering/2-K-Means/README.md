# Agrupamiento K-Means

## [Cuestionario previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)

En esta lecci√≥n, aprender√°s a crear grupos utilizando Scikit-learn y el conjunto de datos de m√∫sica nigeriana que importaste anteriormente. Cubriremos los conceptos b√°sicos de K-Means para el agrupamiento. Ten en cuenta que, como aprendiste en la lecci√≥n anterior, hay muchas formas de trabajar con grupos y el m√©todo que utilices depende de tus datos. Intentaremos K-Means ya que es la t√©cnica de agrupamiento m√°s com√∫n. ¬°Vamos a empezar!

T√©rminos que aprender√°s:

- Puntuaci√≥n de Silhouette
- M√©todo del codo
- Inercia
- Varianza

## Introducci√≥n

[El agrupamiento K-Means](https://wikipedia.org/wiki/K-means_clustering) es un m√©todo derivado del procesamiento de se√±ales. Se utiliza para dividir y particionar grupos de datos en 'k' grupos utilizando una serie de observaciones. Cada observaci√≥n trabaja para agrupar un punto de datos dado lo m√°s cerca posible de su 'media' m√°s cercana, o el punto central de un grupo.

Los grupos se pueden visualizar como [diagramas de Voronoi](https://wikipedia.org/wiki/Voronoi_diagram), que incluyen un punto (o 'semilla') y su regi√≥n correspondiente.

![diagrama de voronoi](../../../../translated_images/voronoi.1dc1613fb0439b9564615eca8df47a4bcd1ce06217e7e72325d2406ef2180795.es.png)

> infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

El proceso de agrupamiento K-Means [se ejecuta en un proceso de tres pasos](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. El algoritmo selecciona un n√∫mero k de puntos centrales muestreando del conjunto de datos. Despu√©s de esto, se repite:
    1. Asigna cada muestra al centroide m√°s cercano.
    2. Crea nuevos centroides tomando el valor medio de todas las muestras asignadas a los centroides anteriores.
    3. Luego, calcula la diferencia entre los nuevos y antiguos centroides y repite hasta que los centroides se estabilicen.

Una desventaja de usar K-Means es que necesitar√°s establecer 'k', es decir, el n√∫mero de centroides. Afortunadamente, el 'm√©todo del codo' ayuda a estimar un buen valor inicial para 'k'. Lo probar√°s en un momento.

## Prerrequisitos

Trabajar√°s en el archivo [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) de esta lecci√≥n que incluye la importaci√≥n de datos y la limpieza preliminar que hiciste en la √∫ltima lecci√≥n.

## Ejercicio - preparaci√≥n

Comienza echando otro vistazo a los datos de las canciones.

1. Crea un diagrama de caja, llamando a `boxplot()` para cada columna:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Estos datos son un poco ruidosos: al observar cada columna como un diagrama de caja, puedes ver valores at√≠picos.

    ![valores at√≠picos](../../../../translated_images/boxplots.8228c29dabd0f29227dd38624231a175f411f1d8d4d7c012cb770e00e4fdf8b6.es.png)

Podr√≠as recorrer el conjunto de datos y eliminar estos valores at√≠picos, pero eso har√≠a que los datos fueran bastante m√≠nimos.

1. Por ahora, elige qu√© columnas usar√°s para tu ejercicio de agrupamiento. Escoge aquellas con rangos similares y codifica la columna `artist_top_genre` como datos num√©ricos:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Ahora necesitas elegir cu√°ntos grupos apuntar. Sabes que hay 3 g√©neros de canciones que extrajimos del conjunto de datos, as√≠ que intentemos con 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Ver√°s un array impreso con los grupos predichos (0, 1 o 2) para cada fila del dataframe.

1. Usa este array para calcular una 'puntuaci√≥n de Silhouette':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Puntuaci√≥n de Silhouette

Busca una puntuaci√≥n de Silhouette m√°s cercana a 1. Esta puntuaci√≥n var√≠a de -1 a 1, y si la puntuaci√≥n es 1, el grupo es denso y est√° bien separado de otros grupos. Un valor cercano a 0 representa grupos superpuestos con muestras muy cercanas al l√≠mite de decisi√≥n de los grupos vecinos. [(Fuente)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Nuestra puntuaci√≥n es **.53**, as√≠ que justo en el medio. Esto indica que nuestros datos no son particularmente adecuados para este tipo de agrupamiento, pero sigamos adelante.

### Ejercicio - construir un modelo

1. Importa `KMeans` y comienza el proceso de agrupamiento.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Hay algunas partes aqu√≠ que merecen una explicaci√≥n.

    > üéì rango: Estas son las iteraciones del proceso de agrupamiento

    > üéì random_state: "Determina la generaci√≥n de n√∫meros aleatorios para la inicializaci√≥n del centroide." [Fuente](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > üéì WCSS: "suma de cuadrados dentro del grupo" mide la distancia promedio al cuadrado de todos los puntos dentro de un grupo al centroide del grupo. [Fuente](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce). 

    > üéì Inercia: Los algoritmos K-Means intentan elegir centroides para minimizar la 'inercia', "una medida de cu√°n coherentes son internamente los grupos." [Fuente](https://scikit-learn.org/stable/modules/clustering.html). El valor se agrega a la variable wcss en cada iteraci√≥n.

    > üéì k-means++: En [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) puedes usar la optimizaci√≥n 'k-means++', que "inicializa los centroides para que est√©n (generalmente) distantes entre s√≠, lo que lleva a probablemente mejores resultados que la inicializaci√≥n aleatoria.

### M√©todo del codo

Anteriormente, dedujiste que, debido a que has apuntado a 3 g√©neros de canciones, deber√≠as elegir 3 grupos. ¬øPero es ese el caso?

1. Usa el 'm√©todo del codo' para asegurarte.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Usa la variable `wcss` que construiste en el paso anterior para crear un gr√°fico que muestre d√≥nde est√° el 'doblez' en el codo, lo que indica el n√∫mero √≥ptimo de grupos. ¬°Quiz√°s s√≠ sean 3!

    ![m√©todo del codo](../../../../translated_images/elbow.72676169eed744ff03677e71334a16c6b8f751e9e716e3d7f40dd7cdef674cca.es.png)

## Ejercicio - mostrar los grupos

1. Intenta el proceso nuevamente, esta vez estableciendo tres grupos, y muestra los grupos como un gr√°fico de dispersi√≥n:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Verifica la precisi√≥n del modelo:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    La precisi√≥n de este modelo no es muy buena, y la forma de los grupos te da una pista del porqu√©. 

    ![grupos](../../../../translated_images/clusters.b635354640d8e4fd4a49ef545495518e7be76172c97c13bd748f5b79f171f69a.es.png)

    Estos datos est√°n demasiado desequilibrados, poco correlacionados y hay demasiada varianza entre los valores de las columnas para agrupar bien. De hecho, los grupos que se forman probablemente est√©n fuertemente influenciados o sesgados por las tres categor√≠as de g√©nero que definimos anteriormente. ¬°Eso fue un proceso de aprendizaje!

    En la documentaci√≥n de Scikit-learn, puedes ver que un modelo como este, con grupos no muy bien demarcados, tiene un problema de 'varianza':

    ![modelos problem√°ticos](../../../../translated_images/problems.f7fb539ccd80608e1f35c319cf5e3ad1809faa3c08537aead8018c6b5ba2e33a.es.png)
    > Infograf√≠a de Scikit-learn

## Varianza

La varianza se define como "el promedio de las diferencias al cuadrado desde la media" [(Fuente)](https://www.mathsisfun.com/data/standard-deviation.html). En el contexto de este problema de agrupamiento, se refiere a datos donde los n√∫meros de nuestro conjunto de datos tienden a divergir demasiado de la media.

‚úÖ Este es un buen momento para pensar en todas las formas en que podr√≠as corregir este problema. ¬øAjustar un poco m√°s los datos? ¬øUsar diferentes columnas? ¬øUsar un algoritmo diferente? Pista: Intenta [escalar tus datos](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) para normalizarlos y probar otras columnas.

> Prueba este '[calculador de varianza](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' para entender un poco m√°s el concepto.

---

## üöÄDesaf√≠o

Pasa un tiempo con este cuaderno, ajustando par√°metros. ¬øPuedes mejorar la precisi√≥n del modelo limpiando m√°s los datos (eliminando valores at√≠picos, por ejemplo)? Puedes usar pesos para dar m√°s peso a ciertas muestras de datos. ¬øQu√© m√°s puedes hacer para crear mejores grupos?

Pista: Intenta escalar tus datos. Hay c√≥digo comentado en el cuaderno que agrega escalado est√°ndar para hacer que las columnas de datos se parezcan m√°s en t√©rminos de rango. Ver√°s que, aunque la puntuaci√≥n de Silhouette baja, el 'doblez' en el gr√°fico del codo se suaviza. Esto se debe a que dejar los datos sin escalar permite que los datos con menos varianza tengan m√°s peso. Lee un poco m√°s sobre este problema [aqu√≠](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Cuestionario posterior a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)

## Revisi√≥n y autoestudio

Echa un vistazo a un simulador de K-Means [como este](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Puedes usar esta herramienta para visualizar puntos de datos de muestra y determinar sus centroides. Puedes editar la aleatoriedad de los datos, el n√∫mero de grupos y el n√∫mero de centroides. ¬øEsto te ayuda a tener una idea de c√≥mo se pueden agrupar los datos?

Tambi√©n, echa un vistazo a [este folleto sobre K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) de Stanford.

## Tarea

[Prueba diferentes m√©todos de agrupamiento](assignment.md)

**Descargo de responsabilidad**:
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional humana. No nos hacemos responsables de cualquier malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.