# R√©gression logistique pour pr√©dire des cat√©gories

![Infographie sur la r√©gression logistique vs. r√©gression lin√©aire](../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.fr.png)

## [Quiz avant le cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introduction

Dans cette derni√®re le√ßon sur la r√©gression, l'une des techniques ML _classiques_ de base, nous allons examiner la r√©gression logistique. Vous utiliseriez cette technique pour d√©couvrir des motifs afin de pr√©dire des cat√©gories binaires. Ce bonbon est-il en chocolat ou non ? Cette maladie est-elle contagieuse ou non ? Ce client choisira-t-il ce produit ou non ?

Dans cette le√ßon, vous apprendrez :

- Une nouvelle biblioth√®que pour la visualisation des donn√©es
- Des techniques pour la r√©gression logistique

‚úÖ Approfondissez votre compr√©hension de ce type de r√©gression dans ce [module d'apprentissage](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Pr√©requis

Ayant travaill√© avec les donn√©es sur les citrouilles, nous sommes maintenant suffisamment familiaris√©s avec celles-ci pour r√©aliser qu'il y a une cat√©gorie binaire avec laquelle nous pouvons travailler : `Color`.

Construisons un mod√®le de r√©gression logistique pour pr√©dire, √©tant donn√© certaines variables, _de quelle couleur une citrouille donn√©e est susceptible d'√™tre_ (orange üéÉ ou blanche üëª).

> Pourquoi parlons-nous de classification binaire dans un groupe de le√ßons sur la r√©gression ? Seulement pour des raisons linguistiques, car la r√©gression logistique est [r√©ellement une m√©thode de classification](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), bien qu'elle soit bas√©e sur une approche lin√©aire. D√©couvrez d'autres fa√ßons de classer les donn√©es dans le prochain groupe de le√ßons.

## D√©finir la question

Pour nos besoins, nous allons l'exprimer sous forme binaire : 'Blanc' ou 'Pas Blanc'. Il y a aussi une cat√©gorie 'ray√©e' dans notre ensemble de donn√©es, mais il y a peu d'instances, donc nous ne l'utiliserons pas. De toute fa√ßon, elle dispara√Æt une fois que nous avons supprim√© les valeurs nulles de l'ensemble de donn√©es.

> üéÉ Fait amusant, nous appelons parfois les citrouilles blanches des citrouilles 'fant√¥mes'. Elles ne sont pas tr√®s faciles √† sculpter, donc elles ne sont pas aussi populaires que les oranges, mais elles sont vraiment belles ! Nous pourrions donc √©galement reformuler notre question comme suit : 'Fant√¥me' ou 'Pas Fant√¥me'. üëª

## √Ä propos de la r√©gression logistique

La r√©gression logistique diff√®re de la r√©gression lin√©aire, que vous avez √©tudi√©e pr√©c√©demment, de plusieurs mani√®res importantes.

[![ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la r√©gression logistique.

### Classification binaire

La r√©gression logistique n'offre pas les m√™mes fonctionnalit√©s que la r√©gression lin√©aire. La premi√®re fournit une pr√©diction sur une cat√©gorie binaire ("blanc ou pas blanc"), tandis que la seconde est capable de pr√©dire des valeurs continues, par exemple, √©tant donn√© l'origine d'une citrouille et le moment de la r√©colte, _quel sera l'augmentation de son prix_.

![Mod√®le de classification des citrouilles](../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.fr.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Autres classifications

Il existe d'autres types de r√©gression logistique, y compris multinomiale et ordinale :

- **Multinomiale**, qui implique d'avoir plus d'une cat√©gorie - "Orange, Blanc et Ray√©".
- **Ordinale**, qui implique des cat√©gories ordonn√©es, utile si nous voulons ordonner nos r√©sultats logiquement, comme nos citrouilles qui sont class√©es par un nombre fini de tailles (mini, sm, med, lg, xl, xxl).

![R√©gression multinomiale vs ordinale](../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.fr.png)

### Les variables N'ONT PAS besoin de corr√©ler

Rappelez-vous comment la r√©gression lin√©aire fonctionnait mieux avec des variables plus corr√©l√©es ? La r√©gression logistique est l'oppos√©e - les variables n'ont pas besoin de s'aligner. Cela fonctionne pour ces donn√©es qui pr√©sentent des corr√©lations relativement faibles.

### Vous avez besoin de beaucoup de donn√©es propres

La r√©gression logistique donnera des r√©sultats plus pr√©cis si vous utilisez plus de donn√©es ; notre petit ensemble de donn√©es n'est pas optimal pour cette t√¢che, alors gardez cela √† l'esprit.

[![ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la pr√©paration des donn√©es pour la r√©gression lin√©aire

‚úÖ Pensez aux types de donn√©es qui se pr√™teraient bien √† la r√©gression logistique.

## Exercice - nettoyer les donn√©es

Tout d'abord, nettoyez un peu les donn√©es, en supprimant les valeurs nulles et en s√©lectionnant seulement certaines colonnes :

1. Ajoutez le code suivant :

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Vous pouvez toujours jeter un ≈ìil √† votre nouveau dataframe :

    ```python
    pumpkins.info
    ```

### Visualisation - graphique cat√©gorique

√Ä ce stade, vous avez √† nouveau charg√© le [carnet de d√©marrage](../../../../2-Regression/4-Logistic/notebook.ipynb) avec les donn√©es sur les citrouilles et l'avez nettoy√© afin de pr√©server un ensemble de donn√©es contenant quelques variables, y compris `Color`. Visualisons le dataframe dans le carnet en utilisant une autre biblioth√®que : [Seaborn](https://seaborn.pydata.org/index.html), qui est construite sur Matplotlib que nous avons utilis√©e pr√©c√©demment.

Seaborn propose des moyens int√©ressants de visualiser vos donn√©es. Par exemple, vous pouvez comparer les distributions des donn√©es pour chaque `Variety` et `Color` dans un graphique cat√©gorique.

1. Cr√©ez un tel graphique en utilisant le `catplot` function, using our pumpkin data `pumpkins`, et en sp√©cifiant un mappage des couleurs pour chaque cat√©gorie de citrouille (orange ou blanche) :

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Une grille de donn√©es visualis√©es](../../../../translated_images/pumpkins_catplot_1.c55c409b71fea2ecc01921e64b91970542101f90bcccfa4aa3a205db8936f48b.fr.png)

    En observant les donn√©es, vous pouvez voir comment les donn√©es de couleur se rapportent √† la vari√©t√©.

    ‚úÖ √âtant donn√© ce graphique cat√©gorique, quelles explorations int√©ressantes pouvez-vous envisager ?

### Pr√©traitement des donn√©es : encodage des caract√©ristiques et des √©tiquettes
Notre ensemble de donn√©es sur les citrouilles contient des valeurs de cha√Æne pour toutes ses colonnes. Travailler avec des donn√©es cat√©gorielles est intuitif pour les humains mais pas pour les machines. Les algorithmes d'apprentissage automatique fonctionnent bien avec des chiffres. C'est pourquoi l'encodage est une √©tape tr√®s importante dans la phase de pr√©traitement des donn√©es, car il nous permet de transformer les donn√©es cat√©gorielles en donn√©es num√©riques, sans perdre d'informations. Un bon encodage conduit √† la construction d'un bon mod√®le.

Pour l'encodage des caract√©ristiques, il existe deux principaux types d'encodeurs :

1. Encodeur ordinal : il convient bien aux variables ordinales, qui sont des variables cat√©gorielles dont les donn√©es suivent un ordre logique, comme la colonne `Item Size` dans notre ensemble de donn√©es. Il cr√©e un mappage tel que chaque cat√©gorie est repr√©sent√©e par un nombre, qui est l'ordre de la cat√©gorie dans la colonne.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Encodeur cat√©gorique : il convient bien aux variables nominales, qui sont des variables cat√©gorielles dont les donn√©es ne suivent pas un ordre logique, comme toutes les caract√©ristiques diff√©rentes de `Item Size` dans notre ensemble de donn√©es. C'est un encodage one-hot, ce qui signifie que chaque cat√©gorie est repr√©sent√©e par une colonne binaire : la variable encod√©e est √©gale √† 1 si la citrouille appartient √† cette vari√©t√© et 0 sinon.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```
Ensuite, `ColumnTransformer` est utilis√© pour combiner plusieurs encodeurs en une seule √©tape et les appliquer aux colonnes appropri√©es.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```
D'autre part, pour encoder l'√©tiquette, nous utilisons la classe `LabelEncoder` de scikit-learn, qui est une classe utilitaire pour aider √† normaliser les √©tiquettes afin qu'elles ne contiennent que des valeurs comprises entre 0 et n_classes-1 (ici, 0 et 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```
Une fois que nous avons encod√© les caract√©ristiques et l'√©tiquette, nous pouvons les fusionner dans un nouveau dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```
‚úÖ Quels sont les avantages d'utiliser un encodeur ordinal pour le `Item Size` column?

### Analyse relationships between variables

Now that we have pre-processed our data, we can analyse the relationships between the features and the label to grasp an idea of how well the model will be able to predict the label given the features.
The best way to perform this kind of analysis is plotting the data. We'll be using again the Seaborn `catplot` function, to visualize the relationships between `Item Size`,  `Variety` et `Color` dans un graphique cat√©gorique. Pour mieux tracer les donn√©es, nous utiliserons la colonne encod√©e `Item Size` column and the unencoded `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```
![Un catplot de donn√©es visualis√©es](../../../../translated_images/pumpkins_catplot_2.87a354447880b3889278155957f8f60dd63db4598de5a6d0fda91c334d31f9f1.fr.png)

### Utiliser un graphique en essaim

Puisque la couleur est une cat√©gorie binaire (Blanc ou Pas Blanc), elle n√©cessite 'une [approche sp√©cialis√©e](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) pour la visualisation'. Il existe d'autres fa√ßons de visualiser la relation de cette cat√©gorie avec d'autres variables.

Vous pouvez visualiser les variables c√¥te √† c√¥te avec les graphiques Seaborn.

1. Essayez un graphique 'en essaim' pour montrer la distribution des valeurs :

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un essaim de donn√©es visualis√©es](../../../../translated_images/swarm_2.efeacfca536c2b577dc7b5f8891f28926663fbf62d893ab5e1278ae734ca104e.fr.png)

**Attention** : le code ci-dessus pourrait g√©n√©rer un avertissement, car seaborn √©choue √† repr√©senter une telle quantit√© de points de donn√©es dans un graphique en essaim. Une solution possible consiste √† diminuer la taille du marqueur, en utilisant le param√®tre 'size'. Cependant, soyez conscient que cela affecte la lisibilit√© du graphique.

> **üßÆ Montrez-moi les math√©matiques**
>
> La r√©gression logistique repose sur le concept de 'vraisemblance maximale' utilisant des [fonctions sigmo√Ødes](https://wikipedia.org/wiki/Sigmoid_function). Une 'Fonction Sigmo√Øde' sur un graphique ressemble √† une forme en 'S'. Elle prend une valeur et la mappe quelque part entre 0 et 1. Sa courbe est √©galement appel√©e 'courbe logistique'. Sa formule ressemble √† ceci :
>
> ![fonction logistique](../../../../translated_images/sigmoid.8b7ba9d095c789cf72780675d0d1d44980c3736617329abfc392dfc859799704.fr.png)
>
> o√π le point m√©dian de la sigmo√Øde se trouve au point 0 des x, L est la valeur maximale de la courbe, et k est la pente de la courbe. Si le r√©sultat de la fonction est sup√©rieur √† 0,5, l'√©tiquette en question sera class√©e comme '1' de la choix binaire. Sinon, elle sera class√©e comme '0'.

## Construisez votre mod√®le

Construire un mod√®le pour trouver ces classifications binaires est √©tonnamment simple dans Scikit-learn.

[![ML pour d√©butants - R√©gression logistique pour la classification des donn√©es](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML pour d√©butants - R√©gression logistique pour la classification des donn√©es")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la construction d'un mod√®le de r√©gression lin√©aire

1. S√©lectionnez les variables que vous souhaitez utiliser dans votre mod√®le de classification et divisez les ensembles d'entra√Ænement et de test en appelant `train_test_split()` :

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Maintenant, vous pouvez entra√Æner votre mod√®le, en appelant `fit()` avec vos donn√©es d'entra√Ænement, et imprimez son r√©sultat :

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Jetez un ≈ìil au tableau de bord de votre mod√®le. Ce n'est pas mal, √©tant donn√© que vous avez seulement environ 1000 lignes de donn√©es :

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Meilleure compr√©hension via une matrice de confusion

Bien que vous puissiez obtenir un rapport de score [termes](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) en imprimant les √©l√©ments ci-dessus, vous pourriez √™tre en mesure de comprendre votre mod√®le plus facilement en utilisant une [matrice de confusion](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) pour nous aider √† comprendre comment le mod√®le fonctionne.

> üéì Une '[matrice de confusion](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matrice d'erreur') est un tableau qui exprime les vrais positifs et n√©gatifs et les faux positifs de votre mod√®le, permettant ainsi d'√©valuer la pr√©cision des pr√©dictions.

1. Pour utiliser une matrice de confusion, appelez `confusion_matrix()` :

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Jetez un ≈ìil √† la matrice de confusion de votre mod√®le :

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

Dans Scikit-learn, les lignes de la matrice de confusion (axe 0) sont les √©tiquettes r√©elles et les colonnes (axe 1) sont les √©tiquettes pr√©dites.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

Que se passe-t-il ici ? Supposons que notre mod√®le soit charg√© de classifier des citrouilles entre deux cat√©gories binaires, la cat√©gorie 'blanche' et la cat√©gorie 'non-blanche'.

- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient en r√©alit√© √† la cat√©gorie 'non-blanche', nous l'appelons un vrai n√©gatif, repr√©sent√© par le nombre en haut √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient en r√©alit√© √† la cat√©gorie 'non-blanche', nous l'appelons un faux n√©gatif, repr√©sent√© par le nombre en bas √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient en r√©alit√© √† la cat√©gorie 'blanche', nous l'appelons un faux positif, repr√©sent√© par le nombre en haut √† droite.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient en r√©alit√© √† la cat√©gorie 'blanche', nous l'appelons un vrai positif, repr√©sent√© par le nombre en bas √† droite.

Comme vous l'avez peut-√™tre devin√©, il est pr√©f√©rable d'avoir un plus grand nombre de vrais positifs et de vrais n√©gatifs et un nombre plus faible de faux positifs et de faux n√©gatifs, ce qui implique que le mod√®le fonctionne mieux.

Comment la matrice de confusion est-elle li√©e √† la pr√©cision et au rappel ? Rappelez-vous, le rapport de classification imprim√© ci-dessus montrait la pr√©cision (0,85) et le rappel (0,67).

Pr√©cision = tp / (tp + fp) = 22 / (22 + 4) = 0,8461538461538461

Rappel = tp / (tp + fn) = 22 / (22 + 11) = 0,6666666666666666

‚úÖ Q : Selon la matrice de confusion, comment le mod√®le a-t-il fonctionn√© ? R : Pas mal ; il y a un bon nombre de vrais n√©gatifs mais aussi quelques faux n√©gatifs.

Revisitons les termes que nous avons vus plus t√¥t avec l'aide du mappage de la matrice de confusion TP/TN et FP/FN :

üéì Pr√©cision : TP/(TP + FP) La fraction d'instances pertinentes parmi les instances r√©cup√©r√©es (par exemple, quelles √©tiquettes √©taient bien √©tiquet√©es)

üéì Rappel : TP/(TP + FN) La fraction d'instances pertinentes qui ont √©t√© r√©cup√©r√©es, qu'elles soient bien √©tiquet√©es ou non

üéì f1-score : (2 * pr√©cision * rappel)/(pr√©cision + rappel) Une moyenne pond√©r√©e de la pr√©cision et du rappel, avec 1 √©tant le meilleur et 0 √©tant le pire

üéì Support : Le nombre d'occurrences de chaque √©tiquette r√©cup√©r√©e

üéì Pr√©cision : (TP + TN)/(TP + TN + FP + FN) Le pourcentage d'√©tiquettes pr√©dites avec pr√©cision pour un √©chantillon.

üéì Moyenne Macro : Le calcul de la moyenne non pond√©r√©e des m√©triques pour chaque √©tiquette, sans tenir compte du d√©s√©quilibre des √©tiquettes.

üéì Moyenne Pond√©r√©e : Le calcul de la moyenne des m√©triques pour chaque √©tiquette, en tenant compte du d√©s√©quilibre des √©tiquettes en les pond√©rant par leur support (le nombre d'instances r√©elles pour chaque √©tiquette).

‚úÖ Pouvez-vous penser √† la m√©trique que vous devriez surveiller si vous souhaitez que votre mod√®le r√©duise le nombre de faux n√©gatifs ?

## Visualisez la courbe ROC de ce mod√®le

[![ML pour d√©butants - Analyser la performance de la r√©gression logistique avec les courbes ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML pour d√©butants - Analyser la performance de la r√©gression logistique avec les courbes ROC")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction aux courbes ROC

Faisons une visualisation suppl√©mentaire pour voir la fameuse courbe 'ROC' :

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

En utilisant Matplotlib, tracez le [Caract√©ristique de fonctionnement du r√©cepteur](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC. Les courbes ROC sont souvent utilis√©es pour obtenir une vue de la sortie d'un classificateur en termes de vrais vs faux positifs. "Les courbes ROC pr√©sentent g√©n√©ralement le taux de vrais positifs sur l'axe Y et le

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©e bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es d√©coulant de l'utilisation de cette traduction.