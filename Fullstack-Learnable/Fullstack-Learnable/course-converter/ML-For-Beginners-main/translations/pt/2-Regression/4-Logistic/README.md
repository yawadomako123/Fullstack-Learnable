# Regress√£o log√≠stica para prever categorias

![Infogr√°fico de regress√£o log√≠stica vs. linear](../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.pt.png)

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)

> ### [Esta li√ß√£o est√° dispon√≠vel em R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introdu√ß√£o

Nesta √∫ltima li√ß√£o sobre Regress√£o, uma das t√©cnicas b√°sicas _cl√°ssicas_ de ML, vamos dar uma olhada na Regress√£o Log√≠stica. Voc√™ usaria essa t√©cnica para descobrir padr√µes para prever categorias bin√°rias. Este doce √© chocolate ou n√£o? Esta doen√ßa √© contagiosa ou n√£o? Este cliente escolher√° este produto ou n√£o?

Nesta li√ß√£o, voc√™ aprender√°:

- Uma nova biblioteca para visualiza√ß√£o de dados
- T√©cnicas para regress√£o log√≠stica

‚úÖ Aprofunde seu entendimento sobre como trabalhar com esse tipo de regress√£o neste [m√≥dulo de Aprendizado](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Pr√©-requisitos

Depois de trabalhar com os dados de ab√≥bora, j√° estamos familiarizados o suficiente para perceber que h√° uma categoria bin√°ria com a qual podemos trabalhar: `Color`.

Vamos construir um modelo de regress√£o log√≠stica para prever isso, dado algumas vari√°veis, _qual cor uma determinada ab√≥bora provavelmente ser√°_ (laranja üéÉ ou branca üëª).

> Por que estamos falando sobre classifica√ß√£o bin√°ria em uma li√ß√£o sobre regress√£o? Apenas por conveni√™ncia lingu√≠stica, j√° que a regress√£o log√≠stica √© [realmente um m√©todo de classifica√ß√£o](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), embora seja baseada em linearidade. Aprenda sobre outras maneiras de classificar dados no pr√≥ximo grupo de li√ß√µes.

## Defina a quest√£o

Para nossos prop√≥sitos, vamos expressar isso como bin√°rio: 'Branca' ou 'N√£o Branca'. H√° tamb√©m uma categoria 'listrada' em nosso conjunto de dados, mas h√° poucas inst√¢ncias dela, ent√£o n√£o a usaremos. Ela desaparece assim que removemos os valores nulos do conjunto de dados, de qualquer forma.

> üéÉ Curiosidade, √†s vezes chamamos ab√≥boras brancas de ab√≥boras 'fantasmas'. Elas n√£o s√£o muito f√°ceis de esculpir, ent√£o n√£o s√£o t√£o populares quanto as laranjas, mas s√£o muito legais! Ent√£o, tamb√©m poder√≠amos reformular nossa pergunta como: 'Fantasma' ou 'N√£o Fantasma'. üëª

## Sobre a regress√£o log√≠stica

A regress√£o log√≠stica difere da regress√£o linear, que voc√™ aprendeu anteriormente, em algumas maneiras importantes.

[![ML para iniciantes - Entendendo a Regress√£o Log√≠stica para Classifica√ß√£o em Machine Learning](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML para iniciantes - Entendendo a Regress√£o Log√≠stica para Classifica√ß√£o em Machine Learning")

> üé• Clique na imagem acima para um breve v√≠deo sobre a regress√£o log√≠stica.

### Classifica√ß√£o bin√°ria

A regress√£o log√≠stica n√£o oferece os mesmos recursos que a regress√£o linear. A primeira oferece uma previs√£o sobre uma categoria bin√°ria ("branca ou n√£o branca"), enquanto a √∫ltima √© capaz de prever valores cont√≠nuos, por exemplo, dado a origem de uma ab√≥bora e o tempo de colheita, _quanto seu pre√ßo ir√° aumentar_.

![Modelo de classifica√ß√£o de ab√≥bora](../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.pt.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Outras classifica√ß√µes

Existem outros tipos de regress√£o log√≠stica, incluindo multinomial e ordinal:

- **Multinomial**, que envolve ter mais de uma categoria - "Laranja, Branca e Listrada".
- **Ordinal**, que envolve categorias ordenadas, √∫til se quisermos ordenar nossos resultados logicamente, como nossas ab√≥boras que s√£o ordenadas por um n√∫mero finito de tamanhos (mini, sm, med, lg, xl, xxl).

![Regress√£o multinomial vs ordinal](../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.pt.png)

### Vari√°veis N√ÉO precisam estar correlacionadas

Lembre-se de como a regress√£o linear funcionava melhor com vari√°veis mais correlacionadas? A regress√£o log√≠stica √© o oposto - as vari√°veis n√£o precisam estar alinhadas. Isso funciona para esses dados que t√™m correla√ß√µes um tanto fracas.

### Voc√™ precisa de muitos dados limpos

A regress√£o log√≠stica dar√° resultados mais precisos se voc√™ usar mais dados; nosso pequeno conjunto de dados n√£o √© ideal para essa tarefa, ent√£o tenha isso em mente.

[![ML para iniciantes - An√°lise e Prepara√ß√£o de Dados para Regress√£o Log√≠stica](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML para iniciantes - An√°lise e Prepara√ß√£o de Dados para Regress√£o Log√≠stica")

> üé• Clique na imagem acima para um breve v√≠deo sobre a prepara√ß√£o de dados para regress√£o linear

‚úÖ Pense sobre os tipos de dados que se prestariam bem √† regress√£o log√≠stica

## Exerc√≠cio - organizar os dados

Primeiro, limpe um pouco os dados, removendo valores nulos e selecionando apenas algumas das colunas:

1. Adicione o seguinte c√≥digo:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Voc√™ sempre pode dar uma olhada em seu novo dataframe:

    ```python
    pumpkins.info
    ```

### Visualiza√ß√£o - gr√°fico categ√≥rico

Neste ponto, voc√™ carregou novamente o [notebook inicial](../../../../2-Regression/4-Logistic/notebook.ipynb) com dados de ab√≥bora e o limpou para preservar um conjunto de dados contendo algumas vari√°veis, incluindo `Color`. Vamos visualizar o dataframe no notebook usando uma biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que √© constru√≠da sobre o Matplotlib que usamos anteriormente.

Seaborn oferece algumas maneiras interessantes de visualizar seus dados. Por exemplo, voc√™ pode comparar distribui√ß√µes dos dados para cada `Variety` e `Color` em um gr√°fico categ√≥rico.

1. Crie tal gr√°fico usando o `catplot` function, using our pumpkin data `pumpkins`, e especificando uma mapea√ß√£o de cores para cada categoria de ab√≥bora (laranja ou branca):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Uma grade de dados visualizados](../../../../translated_images/pumpkins_catplot_1.c55c409b71fea2ecc01921e64b91970542101f90bcccfa4aa3a205db8936f48b.pt.png)

    Observando os dados, voc√™ pode ver como os dados de Cor se relacionam com a Variety.

    ‚úÖ Dado este gr√°fico categ√≥rico, quais s√£o algumas explora√ß√µes interessantes que voc√™ pode imaginar?

### Pr√©-processamento de dados: codifica√ß√£o de caracter√≠sticas e r√≥tulos

Nosso conjunto de dados de ab√≥bora cont√©m valores de string para todas as suas colunas. Trabalhar com dados categ√≥ricos √© intuitivo para os humanos, mas n√£o para as m√°quinas. Algoritmos de aprendizado de m√°quina funcionam bem com n√∫meros. √â por isso que a codifica√ß√£o √© uma etapa muito importante na fase de pr√©-processamento de dados, j√° que nos permite transformar dados categ√≥ricos em dados num√©ricos, sem perder nenhuma informa√ß√£o. Uma boa codifica√ß√£o leva √† constru√ß√£o de um bom modelo.

Para a codifica√ß√£o de caracter√≠sticas, existem dois tipos principais de codificadores:

1. Codificador ordinal: ele se adapta bem a vari√°veis ordinais, que s√£o vari√°veis categ√≥ricas onde seus dados seguem uma ordem l√≥gica, como a coluna `Item Size` em nosso conjunto de dados. Ele cria um mapeamento de modo que cada categoria seja representada por um n√∫mero, que √© a ordem da categoria na coluna.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificador categ√≥rico: ele se adapta bem a vari√°veis nominais, que s√£o vari√°veis categ√≥ricas onde seus dados n√£o seguem uma ordem l√≥gica, como todas as caracter√≠sticas diferentes de `Item Size` em nosso conjunto de dados. √â uma codifica√ß√£o one-hot, o que significa que cada categoria √© representada por uma coluna bin√°ria: a vari√°vel codificada √© igual a 1 se a ab√≥bora pertence √†quela Variety e 0 caso contr√°rio.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Em seguida, o `ColumnTransformer` √© usado para combinar v√°rios codificadores em um √∫nico passo e aplic√°-los √†s colunas apropriadas.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

Por outro lado, para codificar o r√≥tulo, usamos a classe `LabelEncoder` do scikit-learn, que √© uma classe utilit√°ria para ajudar a normalizar r√≥tulos de modo que contenham apenas valores entre 0 e n_classes-1 (aqui, 0 e 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

Uma vez que tenhamos codificado as caracter√≠sticas e o r√≥tulo, podemos mescl√°-los em um novo dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

‚úÖ Quais s√£o as vantagens de usar um codificador ordinal para o `Item Size` column?

### Analyse relationships between variables

Now that we have pre-processed our data, we can analyse the relationships between the features and the label to grasp an idea of how well the model will be able to predict the label given the features.
The best way to perform this kind of analysis is plotting the data. We'll be using again the Seaborn `catplot` function, to visualize the relationships between `Item Size`,  `Variety` e `Color` em um gr√°fico categ√≥rico. Para melhor plotar os dados, usaremos a coluna codificada `Item Size` column and the unencoded `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Um catplot de dados visualizados](../../../../translated_images/pumpkins_catplot_2.87a354447880b3889278155957f8f60dd63db4598de5a6d0fda91c334d31f9f1.pt.png)

### Use um gr√°fico de enxame

Como Color √© uma categoria bin√°ria (Branca ou N√£o), ela precisa de 'uma [abordagem especializada](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para visualiza√ß√£o'. Existem outras maneiras de visualizar a rela√ß√£o dessa categoria com outras vari√°veis.

Voc√™ pode visualizar vari√°veis lado a lado com gr√°ficos do Seaborn.

1. Tente um gr√°fico de 'enxame' para mostrar a distribui√ß√£o dos valores:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Um enxame de dados visualizados](../../../../translated_images/swarm_2.efeacfca536c2b577dc7b5f8891f28926663fbf62d893ab5e1278ae734ca104e.pt.png)

**Cuidado**: o c√≥digo acima pode gerar um aviso, j√° que o seaborn n√£o consegue representar tal quantidade de pontos de dados em um gr√°fico de enxame. Uma poss√≠vel solu√ß√£o √© diminuir o tamanho do marcador, usando o par√¢metro 'size'. No entanto, esteja ciente de que isso afeta a legibilidade do gr√°fico.

> **üßÆ Mostre-me a Matem√°tica**
>
> A regress√£o log√≠stica baseia-se no conceito de 'm√°xima verossimilhan√ßa' usando [fun√ß√µes sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Uma 'Fun√ß√£o Sigmoide' em um gr√°fico parece uma forma de 'S'. Ela pega um valor e o mapeia para algum lugar entre 0 e 1. Sua curva tamb√©m √© chamada de 'curva log√≠stica'. Sua f√≥rmula √© assim:
>
> ![fun√ß√£o log√≠stica](../../../../translated_images/sigmoid.8b7ba9d095c789cf72780675d0d1d44980c3736617329abfc392dfc859799704.pt.png)
>
> onde o ponto m√©dio da sigmoide se encontra no ponto 0 de x, L √© o valor m√°ximo da curva e k √© a inclina√ß√£o da curva. Se o resultado da fun√ß√£o for mais que 0.5, o r√≥tulo em quest√£o receber√° a classe '1' da escolha bin√°ria. Se n√£o, ser√° classificado como '0'.

## Construa seu modelo

Construir um modelo para encontrar essas classifica√ß√µes bin√°rias √© surpreendentemente simples no Scikit-learn.

[![ML para iniciantes - Regress√£o Log√≠stica para classifica√ß√£o de dados](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML para iniciantes - Regress√£o Log√≠stica para classifica√ß√£o de dados")

> üé• Clique na imagem acima para um breve v√≠deo sobre a constru√ß√£o de um modelo de regress√£o linear

1. Selecione as vari√°veis que voc√™ deseja usar em seu modelo de classifica√ß√£o e divida os conjuntos de treinamento e teste chamando `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Agora voc√™ pode treinar seu modelo, chamando `fit()` com seus dados de treinamento, e imprimir seu resultado:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    D√™ uma olhada no placar do seu modelo. N√£o est√° ruim, considerando que voc√™ tem apenas cerca de 1000 linhas de dados:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Melhor compreens√£o atrav√©s de uma matriz de confus√£o

Embora voc√™ possa obter um relat√≥rio de placar [termos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimindo os itens acima, voc√™ pode entender seu modelo mais facilmente usando uma [matriz de confus√£o](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para nos ajudar a entender como o modelo est√° se saindo.

> üéì Uma '[matriz de confus√£o](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matriz de erro') √© uma tabela que expressa os verdadeiros positivos e negativos do seu modelo, assim avaliando a precis√£o das previs√µes.

1. Para usar uma matriz de confus√£o, chame `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    D√™ uma olhada na matriz de confus√£o do seu modelo:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

No Scikit-learn, as linhas da matriz de confus√£o (eixo 0) s√£o r√≥tulos reais e as colunas (eixo 1) s√£o r√≥tulos previstos.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

O que est√° acontecendo aqui? Vamos supor que nosso modelo √© solicitado a classificar ab√≥boras entre duas categorias bin√°rias, a categoria 'branca' e a categoria 'n√£o-branca'.

- Se seu modelo prev√™ uma ab√≥bora como n√£o branca e ela pertence √† categoria 'n√£o-branca' na realidade, chamamos isso de verdadeiro negativo, mostrado pelo n√∫mero no canto superior esquerdo.
- Se seu modelo prev√™ uma ab√≥bora como branca e ela pertence √† categoria 'n√£o-branca' na realidade, chamamos isso de falso negativo, mostrado pelo n√∫mero no canto inferior esquerdo.
- Se seu modelo prev√™ uma ab√≥bora como n√£o branca e ela pertence √† categoria 'branca' na realidade, chamamos isso de falso positivo, mostrado pelo n√∫mero no canto superior direito.
- Se seu modelo prev√™ uma ab√≥bora como branca e ela pertence √† categoria 'branca' na realidade, chamamos isso de verdadeiro positivo, mostrado pelo n√∫mero no canto inferior direito.

Como voc√™ pode ter adivinhado, √© prefer√≠vel ter um n√∫mero maior de verdadeiros positivos e verdadeiros negativos e um n√∫mero menor de falsos positivos e falsos negativos, o que implica que o modelo est√° se saindo melhor.

Como a matriz de confus√£o se relaciona com precis√£o e recall? Lembre-se, o relat√≥rio de classifica√ß√£o impresso acima mostrou precis√£o (0.85) e recall (0.67).

Precis√£o = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

‚úÖ Q: De acordo com a matriz de confus√£o, como o modelo se saiu? A: N√£o muito mal; h√° um bom n√∫mero de verdadeiros negativos, mas tamb√©m alguns falsos negativos.

Vamos revisitar os termos que vimos anteriormente com a ajuda do mapeamento da matriz de confus√£o de TP/TN e FP/FN:

üéì Precis√£o: TP/(TP + FP) A fra√ß√£o de inst√¢ncias relevantes entre as inst√¢ncias recuperadas (por exemplo, quais r√≥tulos foram bem rotulados)

üéì Recall: TP/(TP + FN) A fra√ß√£o de inst√¢ncias relevantes que foram recuperadas, sejam bem rotuladas ou n√£o

üéì f1-score: (2 * precis√£o * recall)/(precis√£o + recall) Uma m√©dia ponderada da precis√£o e recall, com o melhor sendo 1 e o pior sendo 0

üéì Suporte: O n√∫mero de ocorr√™ncias de cada r√≥tulo recuperado

üéì Precis√£o: (TP + TN)/(TP + TN + FP + FN) A porcentagem de r√≥tulos previstos com precis√£o para uma amostra.

üéì M√©dia Macro: O c√°lculo da m√©dia n√£o ponderada das m√©tricas para cada r√≥tulo, sem levar em conta o desequil√≠brio de r√≥tulos.

üéì M√©dia Ponderada: O c√°lculo da m√©dia das m√©tricas para cada r√≥tulo, levando em conta o desequil√≠brio de r√≥tulos, ponderando-os por seu suporte (o n√∫mero de inst√¢ncias verdadeiras para cada r√≥tulo).

‚úÖ Voc√™ consegue pensar em qual m√©trica deve observar se quiser que seu modelo reduza o n√∫mero de falsos negativos?

## Visualize a curva ROC deste modelo

[![ML para iniciantes - Analisando o Desempenho da Regress√£o Log√≠stica com Curvas ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML para iniciantes - Analisando o Desempenho da Regress√£o Log√≠stica com Curvas ROC")

> üé• Clique na imagem acima para um breve v√≠deo sobre curvas ROC

Vamos fazer mais uma visualiza√ß√£o para ver a chamada curva 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Usando Matplotlib, plote o [Caracter√≠stica de Opera√ß√£o Recebida](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC do modelo. As curvas ROC s√£o frequentemente usadas para obter uma vis√£o da sa√≠da de um classificador em termos de seus verdadeiros vs. falsos positivos. "As curvas ROC normalmente apresentam a taxa de verdadeiro positivo no eixo Y e a taxa de falso positivo no eixo X." Assim, a inclina√ß√£o da curva e o espa√ßo entre a linha do ponto m√©dio e a curva s√£o importantes: voc√™ quer uma curva que rapidamente suba e passe pela linha. No nosso caso, h√° falsos positivos para come√ßar, e ent√£o a linha sobe e passa corretamente:

![ROC](../../../../translated_images/ROC_2.777f20cdfc4988ca683ade6850ac832cb70c96c12f1b910d294f270ef36e1a1c.pt.png)

Finalmente, use a API [`roc_auc_score` do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) para calcular a '√Årea Sob a Curva' (AUC) real:

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```

O resultado √© `0.9749908725812341`. Dado que a AUC varia de 0 a 1, voc√™ quer uma pontua√ß√£o alta, pois um modelo que est√° 100% correto em suas previs√µes ter√° uma AUC de 1; neste caso, o modelo √© _muito bom_.

Nas pr√≥ximas li√ß√µes sobre classifica√ß√µes, voc√™ aprender√° como iterar para melhorar as pontua√ß√µes do seu modelo. Mas por enquanto, parab√©ns! Voc√™ completou essas li√ß√µes de regress√£o!



**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.