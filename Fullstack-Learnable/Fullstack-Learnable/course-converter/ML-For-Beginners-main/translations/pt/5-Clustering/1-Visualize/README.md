# Introdu√ß√£o ao agrupamento

Agrupamento √© um tipo de [Aprendizado N√£o Supervisionado](https://wikipedia.org/wiki/Unsupervised_learning) que presume que um conjunto de dados n√£o est√° rotulado ou que suas entradas n√£o est√£o associadas a sa√≠das pr√©-definidas. Ele utiliza v√°rios algoritmos para analisar dados n√£o rotulados e fornecer agrupamentos de acordo com os padr√µes que identifica nos dados.

[![No One Like You by PSquare](https://img.youtube.com/vi/ty2advRiWJM/0.jpg)](https://youtu.be/ty2advRiWJM "No One Like You by PSquare")

> üé• Clique na imagem acima para assistir a um v√≠deo. Enquanto voc√™ estuda aprendizado de m√°quina com agrupamento, aproveite algumas faixas de Dance Hall nigeriano - esta √© uma m√∫sica muito bem avaliada de 2014 do PSquare.
## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)
### Introdu√ß√£o

[Agrega√ß√£o](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) √© muito √∫til para explora√ß√£o de dados. Vamos ver se pode ajudar a descobrir tend√™ncias e padr√µes na forma como o p√∫blico nigeriano consome m√∫sica.

‚úÖ Reserve um minuto para pensar sobre as aplica√ß√µes do agrupamento. Na vida real, o agrupamento acontece sempre que voc√™ tem uma pilha de roupas e precisa separar as roupas dos membros da sua fam√≠lia üß¶üëïüëñü©≤. Na ci√™ncia de dados, o agrupamento ocorre ao tentar analisar as prefer√™ncias de um usu√°rio ou determinar as caracter√≠sticas de qualquer conjunto de dados n√£o rotulado. O agrupamento, de certa forma, ajuda a dar sentido ao caos, como uma gaveta de meias.

[![Introdu√ß√£o ao ML](https://img.youtube.com/vi/esmzYhuFnds/0.jpg)](https://youtu.be/esmzYhuFnds "Introdu√ß√£o ao Agrupamento")

> üé• Clique na imagem acima para assistir a um v√≠deo: John Guttag do MIT apresenta o agrupamento.

Em um ambiente profissional, o agrupamento pode ser usado para determinar coisas como segmenta√ß√£o de mercado, identificando quais faixas et√°rias compram quais itens, por exemplo. Outro uso seria a detec√ß√£o de anomalias, talvez para detectar fraudes a partir de um conjunto de dados de transa√ß√µes de cart√£o de cr√©dito. Ou voc√™ pode usar o agrupamento para identificar tumores em um lote de exames m√©dicos.

‚úÖ Pense por um minuto sobre como voc√™ pode ter encontrado o agrupamento 'na pr√°tica', em um ambiente banc√°rio, de com√©rcio eletr√¥nico ou empresarial.

> üéì Curiosamente, a an√°lise de agrupamento se originou nos campos da Antropologia e Psicologia na d√©cada de 1930. Voc√™ consegue imaginar como poderia ter sido utilizada?

Alternativamente, voc√™ poderia us√°-lo para agrupar resultados de pesquisa - por links de compras, imagens ou avalia√ß√µes, por exemplo. O agrupamento √© √∫til quando voc√™ tem um grande conjunto de dados que deseja reduzir e sobre o qual deseja realizar uma an√°lise mais granular, ent√£o a t√©cnica pode ser usada para aprender sobre os dados antes que outros modelos sejam constru√≠dos.

‚úÖ Uma vez que seus dados est√£o organizados em clusters, voc√™ atribui a eles um ID de cluster, e essa t√©cnica pode ser √∫til ao preservar a privacidade de um conjunto de dados; voc√™ pode se referir a um ponto de dados pelo seu ID de cluster, em vez de por dados identific√°veis mais reveladores. Voc√™ consegue pensar em outras raz√µes pelas quais voc√™ se referiria a um ID de cluster em vez de outros elementos do cluster para identific√°-lo?

Aprofunde seu entendimento sobre t√©cnicas de agrupamento neste [m√≥dulo de Aprendizado](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott)
## Come√ßando com o agrupamento

[Scikit-learn oferece uma grande variedade](https://scikit-learn.org/stable/modules/clustering.html) de m√©todos para realizar agrupamento. O tipo que voc√™ escolher depender√° do seu caso de uso. De acordo com a documenta√ß√£o, cada m√©todo tem v√°rios benef√≠cios. Aqui est√° uma tabela simplificada dos m√©todos suportados pelo Scikit-learn e seus casos de uso apropriados:

| Nome do m√©todo                  | Caso de uso                                                               |
| :------------------------------ | :------------------------------------------------------------------------ |
| K-Means                         | prop√≥sito geral, indutivo                                                |
| Propaga√ß√£o de afinidade         | muitos, clusters desiguais, indutivo                                    |
| Mean-shift                      | muitos, clusters desiguais, indutivo                                    |
| Agrupamento espectral           | poucos, clusters iguais, transdutivo                                     |
| Agrupamento hier√°rquico de Ward | muitos, clusters restritos, transdutivo                                  |
| Agrupamento aglomerativo        | muitos, dist√¢ncias n√£o euclidianas, transdutivo                        |
| DBSCAN                          | geometria n√£o plana, clusters desiguais, transdutivo                    |
| OPTICS                          | geometria n√£o plana, clusters desiguais com densidade vari√°vel, transdutivo |
| Misturas gaussianas             | geometria plana, indutivo                                               |
| BIRCH                           | grande conjunto de dados com outliers, indutivo                        |

> üéì Como criamos clusters est√° muito relacionado a como agrupamos os pontos de dados em grupos. Vamos desvendar algum vocabul√°rio:
>
> üéì ['Transdutivo' vs. 'indutivo'](https://wikipedia.org/wiki/Transduction_(machine_learning))
>
> A infer√™ncia transdutiva √© derivada de casos de treinamento observados que mapeiam para casos de teste espec√≠ficos. A infer√™ncia indutiva √© derivada de casos de treinamento que mapeiam para regras gerais que s√£o aplicadas apenas a casos de teste.
>
> Um exemplo: imagine que voc√™ tem um conjunto de dados que est√° apenas parcialmente rotulado. Algumas coisas s√£o 'discos', algumas 'cds' e algumas est√£o em branco. Sua tarefa √© fornecer r√≥tulos para os espa√ßos em branco. Se voc√™ escolher uma abordagem indutiva, voc√™ treinaria um modelo procurando por 'discos' e 'cds' e aplicaria esses r√≥tulos aos seus dados n√£o rotulados. Essa abordagem ter√° dificuldades em classificar coisas que s√£o na verdade 'fitas'. Uma abordagem transdutiva, por outro lado, lida com esses dados desconhecidos de forma mais eficaz, pois trabalha para agrupar itens semelhantes e, em seguida, aplica um r√≥tulo a um grupo. Nesse caso, os clusters poderiam refletir 'coisas musicais redondas' e 'coisas musicais quadradas'.
>
> üéì ['Geometria n√£o plana' vs. 'plana'](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)
>
> Derivada da terminologia matem√°tica, geometria n√£o plana vs. plana refere-se √† medida de dist√¢ncias entre pontos por m√©todos geom√©tricos 'plano' ([Euclidiano](https://wikipedia.org/wiki/Euclidean_geometry)) ou 'n√£o plano' (n√£o euclidiano).
>
> 'Plano' neste contexto refere-se √† geometria euclidiana (partes da qual s√£o ensinadas como geometria 'plana'), e n√£o plano refere-se √† geometria n√£o euclidiana. O que a geometria tem a ver com aprendizado de m√°quina? Bem, como dois campos que est√£o enraizados na matem√°tica, deve haver uma maneira comum de medir dist√¢ncias entre pontos em clusters, e isso pode ser feito de maneira 'plana' ou 'n√£o plana', dependendo da natureza dos dados. [Dist√¢ncias euclidianas](https://wikipedia.org/wiki/Euclidean_distance) s√£o medidas como o comprimento de um segmento de linha entre dois pontos. [Dist√¢ncias n√£o euclidianas](https://wikipedia.org/wiki/Non-Euclidean_geometry) s√£o medidas ao longo de uma curva. Se seus dados, visualizados, parecem n√£o existir em um plano, voc√™ pode precisar usar um algoritmo especializado para lidar com isso.
>
![Infogr√°fico de Geometria Plana vs N√£o Plana](../../../../translated_images/flat-nonflat.d1c8c6e2a96110c1d57fa0b72913f6aab3c245478524d25baf7f4a18efcde224.pt.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)
>
> üéì ['Dist√¢ncias'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)
>
> Clusters s√£o definidos por sua matriz de dist√¢ncia, ou seja, as dist√¢ncias entre pontos. Essa dist√¢ncia pode ser medida de algumas maneiras. Clusters euclidianos s√£o definidos pela m√©dia dos valores dos pontos e cont√™m um 'centroide' ou ponto central. As dist√¢ncias s√£o assim medidas pela dist√¢ncia at√© esse centroide. Dist√¢ncias n√£o euclidianas referem-se a 'clustroides', o ponto mais pr√≥ximo de outros pontos. Clustroides, por sua vez, podem ser definidos de v√°rias maneiras.
>
> üéì ['Constrainido'](https://wikipedia.org/wiki/Constrained_clustering)
>
> [Agrupamento Constrangido](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) introduz o aprendizado 'semi-supervisionado' neste m√©todo n√£o supervisionado. As rela√ß√µes entre os pontos s√£o sinalizadas como 'n√£o podem se conectar' ou 'devem se conectar', ent√£o algumas regras s√£o impostas ao conjunto de dados.
>
> Um exemplo: se um algoritmo √© liberado em um lote de dados n√£o rotulados ou semi-rotulados, os clusters que ele produz podem ser de baixa qualidade. No exemplo acima, os clusters podem agrupar 'coisas musicais redondas' e 'coisas musicais quadradas' e 'coisas triangulares' e 'biscoitos'. Se forem dadas algumas restri√ß√µes, ou regras a serem seguidas ("o item deve ser feito de pl√°stico", "o item precisa ser capaz de produzir m√∫sica"), isso pode ajudar a 'constranger' o algoritmo a fazer melhores escolhas.
>
> üéì 'Densidade'
>
> Dados que s√£o 'ruidosos' s√£o considerados 'densos'. As dist√¢ncias entre pontos em cada um de seus clusters podem se mostrar, ao exame, mais ou menos densas, ou 'superlotadas', e, portanto, esses dados precisam ser analisados com o m√©todo de agrupamento apropriado. [Este artigo](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) demonstra a diferen√ßa entre usar o agrupamento K-Means vs. algoritmos HDBSCAN para explorar um conjunto de dados ruidoso com densidade de cluster desigual.

## Algoritmos de agrupamento

Existem mais de 100 algoritmos de agrupamento, e seu uso depende da natureza dos dados em quest√£o. Vamos discutir alguns dos principais:

- **Agrupamento hier√°rquico**. Se um objeto √© classificado pela sua proximidade a um objeto pr√≥ximo, em vez de a um mais distante, os clusters s√£o formados com base na dist√¢ncia de seus membros em rela√ß√£o a outros objetos. O agrupamento aglomerativo do Scikit-learn √© hier√°rquico.

   ![Infogr√°fico de Agrupamento Hier√°rquico](../../../../translated_images/hierarchical.bf59403aa43c8c47493bfdf1cc25230f26e45f4e38a3d62e8769cd324129ac15.pt.png)
   > Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Agrupamento por centr√≥ide**. Este algoritmo popular requer a escolha de 'k', ou o n√∫mero de clusters a serem formados, ap√≥s o que o algoritmo determina o ponto central de um cluster e re√∫ne dados ao redor desse ponto. [Agrupamento K-means](https://wikipedia.org/wiki/K-means_clustering) √© uma vers√£o popular do agrupamento por centr√≥ide. O centro √© determinado pela m√©dia mais pr√≥xima, da√≠ o nome. A dist√¢ncia ao quadrado do cluster √© minimizada.

   ![Infogr√°fico de Agrupamento por Centr√≥ide](../../../../translated_images/centroid.097fde836cf6c9187d0b2033e9f94441829f9d86f4f0b1604dd4b3d1931aee34.pt.png)
   > Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Agrupamento baseado em distribui√ß√£o**. Baseado em modelagem estat√≠stica, o agrupamento baseado em distribui√ß√£o se concentra em determinar a probabilidade de que um ponto de dados perten√ßa a um cluster e o atribui adequadamente. M√©todos de mistura gaussiana pertencem a este tipo.

- **Agrupamento baseado em densidade**. Pontos de dados s√£o atribu√≠dos a clusters com base em sua densidade, ou seu agrupamento em torno uns dos outros. Pontos de dados distantes do grupo s√£o considerados outliers ou ru√≠do. DBSCAN, Mean-shift e OPTICS pertencem a este tipo de agrupamento.

- **Agrupamento baseado em grade**. Para conjuntos de dados multidimensionais, uma grade √© criada e os dados s√£o divididos entre as c√©lulas da grade, criando assim clusters.

## Exerc√≠cio - agrupe seus dados

O agrupamento como t√©cnica √© amplamente auxiliado por uma visualiza√ß√£o adequada, ent√£o vamos come√ßar visualizando nossos dados musicais. Este exerc√≠cio nos ajudar√° a decidir qual dos m√©todos de agrupamento devemos usar de forma mais eficaz para a natureza desses dados.

1. Abra o arquivo [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/notebook.ipynb) nesta pasta.

1. Importe o pacote `Seaborn` para uma boa visualiza√ß√£o de dados.

    ```python
    !pip install seaborn
    ```

1. Anexe os dados das m√∫sicas do arquivo [_nigerian-songs.csv_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/data/nigerian-songs.csv). Carregue um dataframe com algumas informa√ß√µes sobre as m√∫sicas. Prepare-se para explorar esses dados importando as bibliotecas e despejando os dados:

    ```python
    import matplotlib.pyplot as plt
    import pandas as pd
    
    df = pd.read_csv("../data/nigerian-songs.csv")
    df.head()
    ```

    Verifique as primeiras linhas dos dados:

    |     | nome                     | √°lbum                        | artista              | g√™nero_top_artista | data_lan√ßamento | dura√ß√£o | popularidade | dan√ßabilidade | ac√∫stica | energia | instrumentalidade | vivacidade | volume | fala | tempo   | assinatura_tempo |
    | --- | ------------------------ | ---------------------------- | ------------------- | ---------------- | ------------ | ------ | ---------- | ------------ | ------------ | ------ | ---------------- | -------- | -------- | ----------- | ------- | -------------- |
    | 0   | Sparky                   | Mandy & The Jungle           | Cruel Santino       | alternative r&b  | 2019         | 144000 | 48         | 0.666        | 0.851        | 0.42   | 0.534            | 0.11     | -6.699   | 0.0829      | 133.015 | 5              |
    | 1   | shuga rush               | EVERYTHING YOU HEARD IS TRUE | Odunsi (The Engine) | afropop          | 2020         | 89488  | 30         | 0.71         | 0.0822       | 0.683  | 0.000169         | 0.101    | -5.64    | 0.36        | 129.993 | 3              |
    | 2   | LITT!                    | LITT!                        | AYL√ò                | indie r&b        | 2018         | 207758 | 40         | 0.836        | 0.272        | 0.564  | 0.000537         | 0.11     | -7.127   | 0.0424      | 130.005 | 4              |
    | 3   | Confident / Feeling Cool | Enjoy Your Life              | Lady Donli          | nigerian pop     | 2019         | 175135 | 14         | 0.894        | 0.798        | 0.611  | 0.000187         | 0.0964   | -4.961   | 0.113       | 111.087 | 4              |
    | 4   | wanted you               | rare.                        | Odunsi (The Engine) | afropop          | 2018         | 152049 | 25         | 0.702        | 0.116        | 0.833  | 0.91             | 0.348    | -6.044   | 0.0447      | 105.115 | 4              |

1. Obtenha algumas informa√ß√µes sobre o dataframe, chamando `info()`:

    ```python
    df.info()
    ```

   A sa√≠da deve ser assim:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 530 entries, 0 to 529
    Data columns (total 16 columns):
     #   Column            Non-Null Count  Dtype  
    ---  ------            --------------  -----  
     0   name              530 non-null    object 
     1   album             530 non-null    object 
     2   artist            530 non-null    object 
     3   artist_top_genre  530 non-null    object 
     4   release_date      530 non-null    int64  
     5   length            530 non-null    int64  
     6   popularity        530 non-null    int64  
     7   danceability      530 non-null    float64
     8   acousticness      530 non-null    float64
     9   energy            530 non-null    float64
     10  instrumentalness  530 non-null    float64
     11  liveness          530 non-null    float64
     12  loudness          530 non-null    float64
     13  speechiness       530 non-null    float64
     14  tempo             530 non-null    float64
     15  time_signature    530 non-null    int64  
    dtypes: float64(8), int64(4), object(4)
    memory usage: 66.4+ KB
    ```

1. Verifique se h√° valores nulos, chamando `isnull()` e verificando se a soma √© 0:

    ```python
    df.isnull().sum()
    ```

    Tudo certo:

    ```output
    name                0
    album               0
    artist              0
    artist_top_genre    0
    release_date        0
    length              0
    popularity          0
    danceability        0
    acousticness        0
    energy              0
    instrumentalness    0
    liveness            0
    loudness            0
    speechiness         0
    tempo               0
    time_signature      0
    dtype: int64
    ```

1. Descreva os dados:

    ```python
    df.describe()
    ```

    |       | data_lan√ßamento | dura√ß√£o      | popularidade | dan√ßabilidade | ac√∫stica | energia   | instrumentalidade | vivacidade | volume  | fala | tempo      | assinatura_tempo |
    | ----- | ------------ | ----------- | ---------- | ------------ | ------------ | -------- | ---------------- | -------- | --------- | ----------- | ---------- | -------------- |
    | count | 530          | 530         | 530        | 530          | 530          | 530      | 530              | 530      | 530       | 530         | 530        | 530            |
    | mean  | 2015.390566  | 222298.1698 | 17.507547  | 0.741619     | 0.265412     | 0.760623 | 0.016305         | 0.147308 | -4.953011 | 0.130748    | 116.487864 | 3.986792       |
    | std   | 3.131688     | 39696.82226 | 18.992212  | 0.117522     | 0.208342     | 0.148533 | 0.090321         | 0.123588 | 2.464186  | 0.092939    | 23.518601  | 0.333701       |
    | min   | 1998         | 89488       | 0          | 0.255        | 0.000665     | 0.111    | 0                | 0.0283   | -19.362   | 0.0278      | 61.695     | 3              |
    | 25%   | 2014         | 199305      | 0          | 0.681        | 0.089525     | 0.669    | 0                | 0.07565  | -6.29875  | 0.0591      | 102.96125  | 4              |
    | 50%   | 2016         | 218509      | 13         | 0.761
## [Question√°rio p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)

## Revis√£o e Estudo Aut√¥nomo

Antes de aplicar algoritmos de agrupamento, como aprendemos, √© uma boa ideia entender a natureza do seu conjunto de dados. Leia mais sobre este t√≥pico [aqui](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)

[Este artigo √∫til](https://www.freecodecamp.org/news/8-clustering-algorithms-in-machine-learning-that-all-data-scientists-should-know/) explica as diferentes maneiras como v√°rios algoritmos de agrupamento se comportam, considerando diferentes formas de dados.

## Tarefa

[Pesquise outras visualiza√ß√µes para agrupamento](assignment.md)

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.