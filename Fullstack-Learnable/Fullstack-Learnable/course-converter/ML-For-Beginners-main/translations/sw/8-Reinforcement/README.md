# Utangulizi wa kujifunza kwa kuimarisha

Kujifunza kwa kuimarisha, RL, ni mojawapo ya mifumo ya msingi ya kujifunza kwa mashine, sambamba na kujifunza kwa usimamizi na kujifunza bila usimamizi. RL inahusu maamuzi: kutoa maamuzi sahihi au angalau kujifunza kutoka kwao.

Fikiria una mazingira yaliyosimuliwa kama soko la hisa. Nini kitatokea ikiwa utaweka kanuni fulani? Je, ina athari nzuri au mbaya? Ikiwa kitu kibaya kitatokea, unahitaji kuchukua hii _kuimarisha hasi_, kujifunza kutoka kwayo, na kubadilisha mwelekeo. Ikiwa ni matokeo chanya, unahitaji kujenga juu ya hiyo _kuimarisha chanya_.

![peter na mbwa mwitu](../../../translated_images/peter.779730f9ba3a8a8d9290600dcf55f2e491c0640c785af7ac0d64f583c49b8864.sw.png)

> Peter na marafiki zake wanahitaji kukimbia mbwa mwitu mwenye njaa! Picha na [Jen Looper](https://twitter.com/jenlooper)

## Mada ya Kanda: Peter na Mbwa Mwitu (Urusi)

[Peter na Mbwa Mwitu](https://en.wikipedia.org/wiki/Peter_and_the_Wolf) ni hadithi ya muziki iliyoandikwa na mtunzi wa Kirusi [Sergei Prokofiev](https://en.wikipedia.org/wiki/Sergei_Prokofiev). Ni hadithi kuhusu kijana shujaa Peter, ambaye kwa ujasiri anatoka nyumbani kwake kwenda msituni kumfuata mbwa mwitu. Katika sehemu hii, tutafundisha algorithimu za kujifunza kwa mashine ambazo zitamsaidia Peter:

- **Kuchunguza** eneo la karibu na kujenga ramani bora ya urambazaji
- **Kujifunza** jinsi ya kutumia skateboard na kusawazisha juu yake, ili kuzunguka kwa haraka zaidi.

[![Peter na Mbwa Mwitu](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> üé• Bofya picha hapo juu kusikiliza Peter na Mbwa Mwitu na Prokofiev

## Kujifunza kwa kuimarisha

Katika sehemu zilizopita, umeona mifano miwili ya matatizo ya kujifunza kwa mashine:

- **Kwa usimamizi**, ambapo tuna seti za data zinazopendekeza suluhisho za sampuli kwa tatizo tunalotaka kutatua. [Uainishaji](../4-Classification/README.md) na [urekebishaji](../2-Regression/README.md) ni kazi za kujifunza kwa usimamizi.
- **Bila usimamizi**, ambapo hatuna data ya mafunzo yenye lebo. Mfano mkuu wa kujifunza bila usimamizi ni [Upangaji](../5-Clustering/README.md).

Katika sehemu hii, tutakutambulisha kwa aina mpya ya tatizo la kujifunza ambalo halihitaji data ya mafunzo yenye lebo. Kuna aina kadhaa za matatizo kama hayo:

- **[Kujifunza kwa nusu-usimamizi](https://wikipedia.org/wiki/Semi-supervised_learning)**, ambapo tuna data nyingi zisizo na lebo ambazo zinaweza kutumika kufundisha awali mfano.
- **[Kujifunza kwa kuimarisha](https://wikipedia.org/wiki/Reinforcement_learning)**, ambapo wakala anajifunza jinsi ya kuenenda kwa kufanya majaribio katika mazingira yaliyosimuliwa.

### Mfano - mchezo wa kompyuta

Tuseme unataka kufundisha kompyuta kucheza mchezo, kama vile chess, au [Super Mario](https://wikipedia.org/wiki/Super_Mario). Ili kompyuta icheze mchezo, tunahitaji itabiri ni hatua gani ifanye katika kila hali ya mchezo. Ingawa hii inaweza kuonekana kama tatizo la uainishaji, sio - kwa sababu hatuna seti ya data na hali na hatua zinazolingana. Ingawa tunaweza kuwa na data kama vile mechi zilizopo za chess au kurekodi kwa wachezaji wakicheza Super Mario, kuna uwezekano kwamba data hiyo haitatosheleza idadi kubwa ya hali zinazowezekana.

Badala ya kutafuta data iliyopo ya mchezo, **Kujifunza kwa Kuimarisha** (RL) kunategemea wazo la *kuifanya kompyuta icheze* mara nyingi na kuchunguza matokeo. Hivyo, ili kutumia Kujifunza kwa Kuimarisha, tunahitaji vitu viwili:

- **Mazingira** na **simulator** ambayo huturuhusu kucheza mchezo mara nyingi. Simulator hii ingeweka sheria zote za mchezo pamoja na hali na hatua zinazowezekana.

- **Kazi ya tuzo**, ambayo ingetueleza jinsi tulivyofanya vizuri wakati wa kila hatua au mchezo.

Tofauti kuu kati ya aina nyingine za kujifunza kwa mashine na RL ni kwamba katika RL kwa kawaida hatujui kama tunashinda au kushindwa hadi tunapomaliza mchezo. Hivyo, hatuwezi kusema kama hatua fulani pekee ni nzuri au sio - tunapokea tuzo mwishoni mwa mchezo. Na lengo letu ni kubuni algorithimu ambazo zitatufanya tufundishe mfano chini ya hali zisizo na uhakika. Tutajifunza kuhusu algorithimu moja ya RL inayoitwa **Q-learning**.

## Masomo

1. [Utangulizi wa kujifunza kwa kuimarisha na Q-Learning](1-QLearning/README.md)
2. [Kutumia mazingira ya simulation ya gym](2-Gym/README.md)

## Shukrani

"Utangulizi wa Kujifunza kwa Kuimarisha" uliandikwa kwa ‚ô•Ô∏è na [Dmitry Soshnikov](http://soshnikov.com)

**Kanusho**:
Hati hii imetafsiriwa kwa kutumia huduma za tafsiri za AI zinazotumia mashine. Ingawa tunajitahidi kwa usahihi, tafadhali fahamu kuwa tafsiri za kiotomatiki zinaweza kuwa na makosa au upungufu. Hati ya asili katika lugha yake ya awali inapaswa kuzingatiwa kama chanzo sahihi. Kwa taarifa muhimu, tafsiri ya kitaalamu ya binadamu inapendekezwa. Hatutawajibika kwa maelewano mabaya au tafsiri zisizo sahihi zinazotokana na matumizi ya tafsiri hii.